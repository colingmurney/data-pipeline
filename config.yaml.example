pipelines:
  main_contact_flow:
    - name: "ImportContacts"
      type: "importContactsExample"
      concurrency: 1
      batchSize: 100
      config:
        endpoint: "https://api.somewhere/v1/contacts"
        apiKey: "MY_API_KEY"
        cacheFilePath: "./cache/import_example.json"

    - name: "TransformContacts"
      type: "transformExample"
      concurrency: 2
      batchSize: 50
      config:
        uppercaseField: "Name"

    - name: "PersistToMongo"
      type: "mongoPersist"
      concurrency: 1 # Adjust concurrency based on DB write performance/needs
      batchSize: 100 # Adjust batch size based on DB write performance/needs
      config:
        uri: "mongodb://localhost:27017" # Replace with your actual MongoDB URI
        database: "my_etl_data"          # Replace with your target database name
        collection: "processed_contacts" # Replace with your target collection name

    - name: "ExportContacts"
      type: "exportContactsExample"
      concurrency: 1
      batchSize: 100
      config:
        endpoint: "https://api.somewhere/v1/destination"
        apiKey: "MY_API_KEY"
  
  log_aggregation:
    - name: "ImportAnalyticsEvents"
      type: "importAnalyticsExample"
      concurrency: 1
      batchSize: 500
      config:
        sourceFile: "./sample_data/events.log"

    - name: "AggregateEvents"
      type: "aggregateExample"
      concurrency: 4
      batchSize: 1000
      config:
        groupByField: "UserID"
        aggregationType: "count"

    - name: "StoreAggregates"
      type: "mongoPersist"
      concurrency: 1
      batchSize: 100
      config:
        uri: "mongodb://localhost:27017"
        database: "analytics_db"
        collection: "daily_aggregates"


