# Go ETL Node Pipeline

## Description

This project provides a flexible ETL (Extract, Transform, Load) pipeline built in Go. It utilizes a node-based architecture with linear execution. The core idea is that data flows sequentially through a series of configurable nodes. Each node receives input (as a list of items), performs its specific task, and produces output (also a list of items) for the next node in the sequence. The initial input can be generated by the first node (e.g., an import node) or potentially loaded from configuration. The final node's output is currently discarded.

## Features

* **Node-Based Architecture:** Easily extendable by adding new node types that conform to the defined interface.
* **Configurable Pipeline:** Define the sequence of nodes, their types, and specific parameters using a YAML configuration file (`config.yaml`).
* **Batch Processing:** Nodes can process data in batches, configured via the `batchSize` parameter in `config.yaml`.
* **Concurrent Batch Execution:** For I/O-bound or CPU-intensive tasks within a node, you can configure concurrent processing of batches using the `concurrency` parameter in `config.yaml`.
* **Basic Logging:** Automatic logging between nodes includes execution time and the number of items processed/outputted.
* **Extensibility:** Designed for easy implementation of custom nodes, especially for project-specific data transformations.

## Architecture

The pipeline executes nodes listed in the `config.yaml` file in the specified order.

1.  **Configuration Loading:** `main.go` loads the `config.yaml` file.
2.  **Pipeline Execution:** `pipeline.go` iterates through the configured nodes.
3.  **Node Instantiation:** For each node definition in the config, the `nodes.GetNodeInstance` function uses a factory pattern (implemented in `nodes/node_factory.go`) to create the correct node instance based on its `type`.
4.  **Node Processing:** The `pipeline.go` orchestrator calls the `Process` method on the current node instance.
    * **Input:** The `Process` method receives the output `[]interface{}` slice from the previous node (or an empty slice for the first node).
    * **Batching/Concurrency:** The orchestrator handles splitting the input into batches (`chunkItems` function) and managing concurrent execution based on `batchSize` and `concurrency` settings before calling the node's `Process` method for each batch.
    * **Output:** The `Process` method returns a new `[]interface{}` slice, which becomes the input for the next node.
5.  **Logging:** Execution time and item counts are logged after each node completes.

## Configuration (`config.yaml`)

The pipeline's structure and behavior are defined in `config.yaml`. It contains a list under the `pipeline` key. Each item in the list represents a node with the following fields:

* `name`: A user-friendly name for the node instance (used in logging).
* `type`: The registered type of the node (e.g., "importContacts", "transform", "exportContacts"). This corresponds to the string used when registering the node.
* `concurrency`: (Optional) Number of goroutines to use for processing batches concurrently. Defaults to 1 (sequential) if omitted or < 1.
* `batchSize`: (Optional) Number of items to process in each batch. Defaults to processing all items in one batch if omitted or < 1.
* `config`: A map containing node-specific configuration parameters (e.g., API keys, endpoints, transformation rules).

**Example `config.yaml`:**
```yaml
pipeline:
  - name: "ImportFromSource"
    type: "importContacts"
    concurrency: 1 # No concurrency needed for this example import
    batchSize: 100
    config:
      endpoint: "[https://api.somewhere/v1/contacts](https://api.somewhere/v1/contacts)"
      apiKey: "YOUR_API_KEY_HERE" # Consider using env variables or secrets management

  - name: "MakeNamesUppercase"
    type: "transform"
    concurrency: 4 # Example: Use 4 workers if transformation is CPU-bound
    batchSize: 50
    config:
      uppercaseField: "Name"

  - name: "ExportToDestination"
    type: "exportContacts"
    concurrency: 2 # Example: Use 2 workers for concurrent API calls
    batchSize: 100
    config:
      endpoint: "[https://api.destination/v1/contacts](https://api.destination/v1/contacts)"
      apiKey: "YOUR_OTHER_API_KEY"